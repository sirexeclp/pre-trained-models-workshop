{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from pathlib import Path\n",
    "plt.rcParams['figure.figsize'] = [8, 4.5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_root = Path(\"benchmarks/results/whisper_benchmark\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "datasets = {p.stem.removeprefix(\"NVIDIA\"): pd.read_csv(p) for p in data_root.glob(\"*.csv\")}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_data(datasets):\n",
    "    for dataset in datasets.values():\n",
    "        dataset.rename(columns={\"time\":\"Latency [s]\", \"wer\": \"WER\", \"energy\": \"Energy [kJ]\", \"model_size\": \"Model Size\"}, inplace=True)\n",
    "        dataset[\"1-WER\"] = 1 - dataset[\"WER\"]\n",
    "        dataset[\"Energy [kJ]\"] = dataset[\"Energy [kJ]\"] / 1_000\n",
    "        dataset[\"WERDP [s]\"] = dataset[\"Latency [s]\"] * dataset[\"WER\"]\n",
    "        dataset[\"WERE [kJ]\"] = dataset[\"WER\"] * dataset[\"Energy [kJ]\"]\n",
    "        dataset[\"WEREDP [kJs]\"] = dataset[\"WER\"] * dataset[\"Energy [kJ]\"] * dataset[\"Latency [s]\"]\n",
    "        dataset[\"Relative Latency\"] = dataset[\"Latency [s]\"] / 10 * 60"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prepare_data(datasets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_vars(datasets: dict, x,y,title, annotate=True, ax=None):\n",
    "    if ax is None:\n",
    "        fig, ax = plt.subplots()\n",
    "    markers_n_spacings = iter([(\"o\", 0.02), (\"^\",0.04), (\"x\", 0.04)])\n",
    "    for gpu, data in datasets.items():\n",
    "        marker, spacing = next(markers_n_spacings)\n",
    "        ax.plot(data[x] ,data[y] , marker, label=gpu)\n",
    "        ax.set_title(\"Whisper \" + title)\n",
    "        ax.set_xlabel(x)\n",
    "        ax.set_ylabel(y)\n",
    "        #plt.ylim(bottom=0)\n",
    "        ax.legend()\n",
    "        if annotate:\n",
    "            max_x = data[x].max()\n",
    "            min_x = data[x].min()\n",
    "\n",
    "            for index, size in data[\"Model Size\"].items():\n",
    "                ax.annotate(size, (data[x][index] + spacing * (max_x - min_x) , data[y][index]), va=\"center\")\n",
    "    return ax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_latency_vs_wer(datasets: dict, ax=None):\n",
    "    return plot_vars(datasets, \"Latency [s]\", \"1-WER\", \"Latency vs. 1-WER\",ax=ax)\n",
    "\n",
    "def plot_energy_vs_wer(datasets: dict, ax=None):\n",
    "    return plot_vars(datasets, \"Energy [kJ]\", \"1-WER\", \"Energy vs. 1-WER\",ax=ax)\n",
    "\n",
    "def plot_latency_vs_energy(datasets: dict, ax=None):\n",
    "    return plot_vars(datasets, \"Latency [s]\", \"Energy [kJ]\", \"Latency vs. Energy\",ax=ax)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_werdp_vs_model_size(datasets, ax =None):\n",
    "    return plot_vars(datasets, \"Model Size\", \"WERDP [s]\", \"Word Error Rate Delay Product vs. Model Size\", annotate=False, ax=ax)\n",
    "\n",
    "def plot_werdp_vs_energy(datasets, ax =None):\n",
    "    return plot_vars(datasets, \"Energy [kJ]\", \"WERDP [s]\", \"Word Error Rate Delay Product vs. Model Size\", annotate=True, ax=ax)\n",
    "\n",
    "def plot_were_vs_model_size(datasets, ax =None):\n",
    "    return plot_vars(datasets, \"Model Size\", \"WERE [kJ]\", \"Word Error Rate Energy vs. Model Size\", annotate=False, ax=ax)\n",
    "\n",
    "def plot_weredp_vs_model_size(datasets, ax =None):\n",
    "    return plot_vars(datasets, \"Model Size\", \"WEREDP [kJs]\", \"Word Error Rate Energy Delay Product vs. Model Size\", annotate=False, ax=ax)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.style.use(\"seaborn-v0_8-colorblind\")\n",
    "plt.style.use(\"seaborn-v0_8-talk\")\n",
    "fig, ax = plt.subplots(ncols=3,figsize=(24,4.5))\n",
    "plot_latency_vs_wer(datasets, ax[0])\n",
    "plot_energy_vs_wer(datasets,ax[1])\n",
    "plot_latency_vs_energy(datasets, ax[2])\n",
    "fig.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(ncols=2,nrows=2,figsize=(16,9))\n",
    "plot_werdp_vs_model_size(datasets, ax[0,0])\n",
    "plot_werdp_vs_energy(datasets, ax[0,1])\n",
    "plot_were_vs_model_size(datasets, ax[1,0])\n",
    "plot_weredp_vs_model_size(datasets, ax[1,1])\n",
    "fig.tight_layout()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
