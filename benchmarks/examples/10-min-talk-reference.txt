Welcome back to our stage in Potsdam. Sven is a PhD student in Potsdam. He's researching energy-aware operating systems and how to control the energy demand of memory operations. In his free time, he mentors a local coder dojo to teach kids the marvels of computing. And you can meet him from time to time at FOSS meetups on energy efficiency in and around Berlin. Your word. Okay. Thank you for the introduction. Is this working? Can you see my screen? Actually, you can. It's just a black slide. So my computer is not doing anything meaningful at the moment, yet still it's using energy. Just to give you this black screen and to give it to you on the stream and maybe to transfer my audio. But this is boring, and we all want to use less energy, or at least if we need to use it, maybe do so while the sun is shining and the wind is blowing so we have some renewables. But cutting the energy demand of idle systems is a tricky task. This is left to hardware developers or operating system developers. So let's do something. Let's do something nice. Let's shine up some lights. As I pushed a button here, there were multiple actions going on on my computer. So my SSD was not spinning up, but giving some data back to my presentation tool. Some sockets were socketing and some transistors were screaming along, all to give me this very nice, bright sky here. And if I push a button, this also has another effect, like putting a fairy dust on there. So every click I do, every action I perform on my computer has some work related to it, and this work requires energy. And now the question is, how much energy does each action require? And maybe if we can start to measure it, we can compare and start to cut it down. I could give you now an introduction on how to measure the energy demand of your software. But you can all use Google or DuckDuckGo or whatever search engine you like, and you will find plenty of tutorials on how to do this. And in this talk, I'm just giving you some insight of all the mistakes I made before, so you don't shoot yourself into the foot like I did. I want to talk about some common misconceptions when you're doing energy assessments of your software, or maybe more accessible what to keep in mind when you're measuring your software's energy demand. But let's start out again with some basic physics. Maybe you remember from physics class in school that the energy requirement of an operation is the integral over the power demand over time from a certain start point in time to an end point of time. Okay, that's maybe the most complex slide in here. Let's break it down. So the metric E stands for energy, which is typically measured in joule. And this metric answers questions like, how long will our battery is going to last? Or how high our electricity bill will be? Or maybe, if we're interested in this, what is the carbon footprint of my software when I'm running it? Another interesting thing is the right-hand side, which is the power demand of an operation. This is typically measured in watts, and it's not something we think about so often as typical software developers. This is maybe left to data center operators when they want to get a glimpse of what the power supply limits are of operations, or maybe how much heat dissipation they have to build in, so the cooling facilities they have to somehow factor. So given this information, now let's talk about the misconceptions we can do while we want to somehow find E of a certain operation. And the first misconception is a very simple one. Quite often, we assume that a computer is somehow simply a box with some screen attached and a keyboard, which is good here in case of my laptop, this is true, but my cell phone maybe doesn't have a keyboard, and computers can come in all different kinds of shapes, like some attached to another USB port, then giving you additional compute resources, or you have tiny microcontrollers like those here in the microphone, and when I start cutting the energy demand of a microcontroller, due to the economy of scale, I can cut joules and joules of energy in the long term. Maybe I have an integrated GPU on some development boards, maybe I have a computer, quite old-fashioned, or maybe I have even a big high-end server system, which does not only come with multiple CPUs and some dedicated GPUs for computation, but also have some additional complicated compute devices like FPGAs. And all those different devices have very different power characteristics and energy characteristics. And just to show it to you, I wrote a small program, which is basically a convolution filter, so small hotspots are preying all over the place, and then the heat is dissipating from one simulated cell to another. And this simulation was implemented by me on different compute platforms, so one time on the GPU, on the CPU, and on an FPGA. And when you look at it, you will find that I'm using quite different intake of joules per million cells, depending on the compute device. Now you could argue that maybe my implementation was not perfect, of course it wasn't, it was written by me. Or maybe you can say that I didn't really measure, because here I'm just taking the power draw as given by the specification of the compute device, so maybe the GPU wasn't using 60 watts at each moment in time. So we now learned there's a difference between different compute devices, but now we really want to measure what's going on in one particular one. And here's another thing with our software people, typically we take a ruler, hold it to maybe this laptop, and then we can say, oh, okay, this is so and so many millimeters long. So we always think what we measure is about right. But measurement devices are skewed. When we want to measure the energy demand of software, there are two main ways of building a measurement device. The first one is an actual physical measurement. So we have maybe a shunt, or in German, Nebenwiderstand, where we measure the voltage drop over it, or we build a Hall effect sensor, which is using a magnetic field, which is very good if you're building some CMOS transistors, you can almost get it for free, build in there. So it's very nice, you can build one of those, and then have very accurate, very timely related measurements of some current draw or of the total power draw of your circuit. But this includes somehow to alter your setup. And maybe your setup is so tiny that maybe a human hair compares to it like a Nord Stream 2 pipeline, so it's a little bit difficult to put it in there if you don't have the space. For this reason, especially in embedded platforms and historically, people have been using logical measurements. So somehow they had some physical initial setup, where they made some correlations between hardware performance counters, which gave you the number of instructions issued per second or maybe number of cache references or cache misses. And then using this correlation, they had some model of the energy demand of the software, which is good. I mean, you don't have to alter your circuits. But of course, a model can be error prone. And here's the thing. If any of you ever heard of RAPL or REPL, the quite common measurement facilities on Intel CPUs, they used to be on the right hand side. So people were looking at it and thought, okay, maybe it's giving me some joules. Maybe this is right. But in fact, this was just a model. So there were some early mistakes in earlier papers. The second thing when we start thinking about measurement facilities is that they are covering different domains. And you can zoom in using your measurements, maybe for the entire system. So you're intercepting the wall socket and maybe your compute device. And then you can get the entire energy consumption of your computer. Like maybe you know one of those smart plugs, which typically give you the power draw on a small LCD display. And you can hack it into your computer. Or you can maybe get it via MTTQ or maybe have a USB transfer to get the data out there. This is good. But of course gives you the whole system and not maybe the particular part which is caused by your program. You can also find, especially in mobile devices, that very early measurements often used the battery levels. So they started an operation, looked at the battery current, the battery voltage, finished the operation. And after this one was done, looked at it again. And using this difference, they could say, okay, maybe we used so many milliampere hours. Some better details are being obtained if you're building chips onto your board. Quite often you can find the IPMI or the base management control counters in data centers. So if you're running a data center, maybe look it up. Those are typically the counters you want to use. 